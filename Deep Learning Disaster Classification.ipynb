{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, GRU, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/Users/adefebrian/disaster.csv')  # Replace with the actual path to your CSV file\n",
    "\n",
    "# Define the preprocess_text function\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenization (split into words)\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Remove duplicate words\n",
    "    words = list(dict.fromkeys(words))\n",
    "    # Join the words back to text\n",
    "    text = ' '.join(words)\n",
    "    return text\n",
    "\n",
    "# Assuming you've defined your preprocess_text function\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "# Split data\n",
    "X = df['processed_text']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_len = max([len(seq) for seq in X_train_seq])\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "# # Convert labels to binary format\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train_binary = label_binarizer.fit_transform(y_train)\n",
    "y_test_binary = label_binarizer.transform(y_test)\n",
    "\n",
    "# Load pre-trained word embeddings\n",
    "def load_word_embeddings(embedding_file, embedding_dim):\n",
    "    print(\"Loading Word Embeddings\")\n",
    "    embeddings_index = {}\n",
    "    with open(embedding_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # Skip empty lines\n",
    "                \n",
    "            values = re.split(r'\\s+', line)\n",
    "            word = values[0]\n",
    "            \n",
    "            try:\n",
    "                coefs = np.asarray(values[1:], dtype=np.float32)\n",
    "            except ValueError:\n",
    "                continue  # Skip lines with non-numeric values\n",
    "            \n",
    "            if len(coefs) != embedding_dim:\n",
    "                continue  # Skip embeddings with incorrect dimensions\n",
    "                \n",
    "            embeddings_index[word] = coefs\n",
    "    print(\"Word Embeddings Loaded\")\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file = '/Users/adefebrian/glove.840B.300d.txt'\n",
    "fasttext_file = '/Users/adefebrian/wiki.en.vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word Embeddings\n",
      "Word Embeddings Loaded\n",
      "Loading Word Embeddings\n",
      "Word Embeddings Loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_dim = 300\n",
    "embedding_matrix_glove = np.zeros((vocab_size, embedding_dim))\n",
    "embedding_matrix_fasttext = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "glove_embeddings = load_word_embeddings(glove_file, embedding_dim)\n",
    "fasttext_embeddings = load_word_embeddings(fasttext_file, embedding_dim)\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    glove_embedding_vector = glove_embeddings.get(word)\n",
    "    fasttext_embedding_vector = fasttext_embeddings.get(word)\n",
    "    \n",
    "    if glove_embedding_vector is not None:\n",
    "        embedding_matrix_glove[i] = glove_embedding_vector\n",
    "        \n",
    "    if fasttext_embedding_vector is not None:\n",
    "        embedding_matrix_fasttext[i] = fasttext_embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 59ms/step - loss: 0.5231 - accuracy: 0.7481 - val_loss: 0.4587 - val_accuracy: 0.8063\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.4428 - accuracy: 0.8074 - val_loss: 0.4808 - val_accuracy: 0.7840\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.4153 - accuracy: 0.8186 - val_loss: 0.4419 - val_accuracy: 0.8207\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3993 - accuracy: 0.8227 - val_loss: 0.4112 - val_accuracy: 0.8109\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 7s 69ms/step - loss: 0.3784 - accuracy: 0.8407 - val_loss: 0.4627 - val_accuracy: 0.8142\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3614 - accuracy: 0.8456 - val_loss: 0.4484 - val_accuracy: 0.8102\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.3521 - accuracy: 0.8522 - val_loss: 0.4775 - val_accuracy: 0.8155\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3353 - accuracy: 0.8562 - val_loss: 0.4778 - val_accuracy: 0.7971\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3039 - accuracy: 0.8737 - val_loss: 0.4581 - val_accuracy: 0.8030\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2795 - accuracy: 0.8874 - val_loss: 0.4722 - val_accuracy: 0.7997\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2690 - accuracy: 0.8890 - val_loss: 0.5008 - val_accuracy: 0.7873\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2316 - accuracy: 0.9039 - val_loss: 0.5169 - val_accuracy: 0.7886\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2075 - accuracy: 0.9141 - val_loss: 0.6056 - val_accuracy: 0.7800\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2036 - accuracy: 0.9202 - val_loss: 0.5375 - val_accuracy: 0.7945\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.1761 - accuracy: 0.9289 - val_loss: 0.5770 - val_accuracy: 0.7892\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.1606 - accuracy: 0.9366 - val_loss: 0.6857 - val_accuracy: 0.7682\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 7s 68ms/step - loss: 0.1538 - accuracy: 0.9397 - val_loss: 0.7758 - val_accuracy: 0.7859\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.1444 - accuracy: 0.9452 - val_loss: 0.6594 - val_accuracy: 0.7722\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.1239 - accuracy: 0.9522 - val_loss: 0.7536 - val_accuracy: 0.7715\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.1371 - accuracy: 0.9448 - val_loss: 0.6793 - val_accuracy: 0.7853\n",
      "48/48 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.81      0.81      0.81       874\n",
      "    Disaster       0.75      0.75      0.75       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.78      0.78      0.78      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 55ms/step - loss: 0.5456 - accuracy: 0.7171 - val_loss: 0.4415 - val_accuracy: 0.8056\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.4494 - accuracy: 0.8048 - val_loss: 0.4395 - val_accuracy: 0.8142\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.4337 - accuracy: 0.8095 - val_loss: 0.4351 - val_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.4053 - accuracy: 0.8258 - val_loss: 0.4373 - val_accuracy: 0.8181\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 59ms/step - loss: 0.3910 - accuracy: 0.8307 - val_loss: 0.4460 - val_accuracy: 0.7958\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3823 - accuracy: 0.8414 - val_loss: 0.4306 - val_accuracy: 0.8083\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3577 - accuracy: 0.8476 - val_loss: 0.4842 - val_accuracy: 0.8011\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 57ms/step - loss: 0.3458 - accuracy: 0.8548 - val_loss: 0.4512 - val_accuracy: 0.8050\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3214 - accuracy: 0.8672 - val_loss: 0.5035 - val_accuracy: 0.7669\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.3142 - accuracy: 0.8747 - val_loss: 0.4439 - val_accuracy: 0.7991\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2943 - accuracy: 0.8824 - val_loss: 0.4632 - val_accuracy: 0.8148\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 57ms/step - loss: 0.2718 - accuracy: 0.8962 - val_loss: 0.4940 - val_accuracy: 0.7873\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.2544 - accuracy: 0.9007 - val_loss: 0.4759 - val_accuracy: 0.8102\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2312 - accuracy: 0.9071 - val_loss: 0.5907 - val_accuracy: 0.7971\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2347 - accuracy: 0.9048 - val_loss: 0.5315 - val_accuracy: 0.7892\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.1990 - accuracy: 0.9194 - val_loss: 0.5904 - val_accuracy: 0.7866\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.1828 - accuracy: 0.9268 - val_loss: 0.6363 - val_accuracy: 0.7787\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 59ms/step - loss: 0.1676 - accuracy: 0.9337 - val_loss: 0.6551 - val_accuracy: 0.7833\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.1636 - accuracy: 0.9363 - val_loss: 0.5894 - val_accuracy: 0.7708\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 59ms/step - loss: 0.1427 - accuracy: 0.9447 - val_loss: 0.8021 - val_accuracy: 0.7656\n",
      "48/48 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.83      0.75      0.79       874\n",
      "    Disaster       0.70      0.79      0.74       649\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.76      0.77      0.76      1523\n",
      "weighted avg       0.77      0.77      0.77      1523\n",
      "\n",
      "\n",
      "\n",
      "Training LSTM with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 62ms/step - loss: 0.5252 - accuracy: 0.7433 - val_loss: 0.4546 - val_accuracy: 0.7997\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 7s 65ms/step - loss: 0.4414 - accuracy: 0.8062 - val_loss: 0.4565 - val_accuracy: 0.8155\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.4297 - accuracy: 0.8117 - val_loss: 0.4334 - val_accuracy: 0.8050\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.4234 - accuracy: 0.8182 - val_loss: 0.4769 - val_accuracy: 0.8089\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 67ms/step - loss: 0.4068 - accuracy: 0.8177 - val_loss: 0.4547 - val_accuracy: 0.8116\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3942 - accuracy: 0.8278 - val_loss: 0.4331 - val_accuracy: 0.7978\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 67ms/step - loss: 0.3916 - accuracy: 0.8319 - val_loss: 0.4405 - val_accuracy: 0.8037\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 7s 73ms/step - loss: 0.3813 - accuracy: 0.8327 - val_loss: 0.4432 - val_accuracy: 0.8142\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3678 - accuracy: 0.8381 - val_loss: 0.4385 - val_accuracy: 0.8135\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3524 - accuracy: 0.8463 - val_loss: 0.4762 - val_accuracy: 0.8037\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3475 - accuracy: 0.8519 - val_loss: 0.4510 - val_accuracy: 0.7938\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3277 - accuracy: 0.8575 - val_loss: 0.4923 - val_accuracy: 0.7892\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3104 - accuracy: 0.8662 - val_loss: 0.4896 - val_accuracy: 0.8024\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2948 - accuracy: 0.8765 - val_loss: 0.6193 - val_accuracy: 0.7787\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2775 - accuracy: 0.8878 - val_loss: 0.5256 - val_accuracy: 0.7919\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 67ms/step - loss: 0.2628 - accuracy: 0.8934 - val_loss: 0.4915 - val_accuracy: 0.7958\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 7s 69ms/step - loss: 0.2578 - accuracy: 0.8882 - val_loss: 0.5798 - val_accuracy: 0.7748\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2309 - accuracy: 0.9051 - val_loss: 0.5538 - val_accuracy: 0.7905\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2227 - accuracy: 0.9099 - val_loss: 0.5873 - val_accuracy: 0.7846\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 7s 68ms/step - loss: 0.2011 - accuracy: 0.9192 - val_loss: 0.6440 - val_accuracy: 0.8037\n",
      "48/48 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.79      0.89      0.84       874\n",
      "    Disaster       0.83      0.68      0.75       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.81      0.79      0.79      1523\n",
      "weighted avg       0.81      0.80      0.80      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 55ms/step - loss: 0.5740 - accuracy: 0.6923 - val_loss: 0.4723 - val_accuracy: 0.7978\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.4560 - accuracy: 0.8025 - val_loss: 0.4412 - val_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.4441 - accuracy: 0.8097 - val_loss: 0.4426 - val_accuracy: 0.8004\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 59ms/step - loss: 0.4222 - accuracy: 0.8184 - val_loss: 0.4419 - val_accuracy: 0.8024\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.4107 - accuracy: 0.8250 - val_loss: 0.4336 - val_accuracy: 0.8070\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3923 - accuracy: 0.8346 - val_loss: 0.4769 - val_accuracy: 0.7846\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3845 - accuracy: 0.8355 - val_loss: 0.4309 - val_accuracy: 0.8102\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3809 - accuracy: 0.8397 - val_loss: 0.4440 - val_accuracy: 0.8076\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3646 - accuracy: 0.8468 - val_loss: 0.4449 - val_accuracy: 0.8070\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3477 - accuracy: 0.8545 - val_loss: 0.4639 - val_accuracy: 0.8063\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.3370 - accuracy: 0.8626 - val_loss: 0.4680 - val_accuracy: 0.7938\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3216 - accuracy: 0.8716 - val_loss: 0.4611 - val_accuracy: 0.8030\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3183 - accuracy: 0.8711 - val_loss: 0.4647 - val_accuracy: 0.8011\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2955 - accuracy: 0.8847 - val_loss: 0.5179 - val_accuracy: 0.7840\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3067 - accuracy: 0.8726 - val_loss: 0.5058 - val_accuracy: 0.7866\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2725 - accuracy: 0.8888 - val_loss: 0.5155 - val_accuracy: 0.8024\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2560 - accuracy: 0.8972 - val_loss: 0.6114 - val_accuracy: 0.7938\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 60ms/step - loss: 0.2565 - accuracy: 0.8944 - val_loss: 0.5326 - val_accuracy: 0.7820\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2389 - accuracy: 0.9048 - val_loss: 0.5939 - val_accuracy: 0.7912\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.2165 - accuracy: 0.9122 - val_loss: 0.6109 - val_accuracy: 0.7859\n",
      "48/48 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.77      0.89      0.83       874\n",
      "    Disaster       0.81      0.65      0.72       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.77      0.77      1523\n",
      "weighted avg       0.79      0.79      0.78      1523\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "models = [\n",
    "    (LSTM, 'GloVe', embedding_matrix_glove),\n",
    "    (GRU, 'GloVe', embedding_matrix_glove),\n",
    "    (LSTM, 'FastText', embedding_matrix_fasttext),\n",
    "    (GRU, 'FastText', embedding_matrix_fasttext)\n",
    "]\n",
    "\n",
    "for rnn_type, emb_type, emb_matrix in models:\n",
    "    print(f\"Training {rnn_type.__name__} with {emb_type} embeddings\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[emb_matrix], input_length=max_len, trainable=False),\n",
    "        rnn_type(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_padded, y_train_binary, epochs=20, batch_size=64, validation_data=(X_test_padded, y_test_binary))\n",
    "\n",
    "    y_pred = model.predict(X_test_padded)\n",
    "    y_pred_binary = np.round(y_pred).flatten()\n",
    "\n",
    "    target_names = ['Not Disaster', 'Disaster']\n",
    "    print(classification_report(y_test_binary, y_pred_binary, target_names=target_names))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 60ms/step - loss: 0.5016 - accuracy: 0.7745 - val_loss: 0.4474 - val_accuracy: 0.8011\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.4371 - accuracy: 0.8089 - val_loss: 0.4329 - val_accuracy: 0.8096\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.4151 - accuracy: 0.8243 - val_loss: 0.4307 - val_accuracy: 0.8109\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3954 - accuracy: 0.8307 - val_loss: 0.4238 - val_accuracy: 0.8214\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.3814 - accuracy: 0.8389 - val_loss: 0.4325 - val_accuracy: 0.8116\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3612 - accuracy: 0.8425 - val_loss: 0.4264 - val_accuracy: 0.8102\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.3481 - accuracy: 0.8532 - val_loss: 0.4422 - val_accuracy: 0.8129\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.3330 - accuracy: 0.8603 - val_loss: 0.4449 - val_accuracy: 0.7978\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3078 - accuracy: 0.8688 - val_loss: 0.4369 - val_accuracy: 0.8076\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2827 - accuracy: 0.8831 - val_loss: 0.5467 - val_accuracy: 0.7754\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.2637 - accuracy: 0.8908 - val_loss: 0.4849 - val_accuracy: 0.7971\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.2489 - accuracy: 0.9033 - val_loss: 0.5306 - val_accuracy: 0.8096\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2354 - accuracy: 0.9033 - val_loss: 0.5463 - val_accuracy: 0.7971\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 7s 68ms/step - loss: 0.2035 - accuracy: 0.9189 - val_loss: 0.6318 - val_accuracy: 0.7899\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.1900 - accuracy: 0.9266 - val_loss: 0.5588 - val_accuracy: 0.7938\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.1841 - accuracy: 0.9297 - val_loss: 0.6171 - val_accuracy: 0.7735\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.1694 - accuracy: 0.9350 - val_loss: 0.6398 - val_accuracy: 0.7630\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.1546 - accuracy: 0.9424 - val_loss: 0.6633 - val_accuracy: 0.7866\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.1479 - accuracy: 0.9427 - val_loss: 0.7278 - val_accuracy: 0.7958\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.1236 - accuracy: 0.9534 - val_loss: 0.7323 - val_accuracy: 0.7859\n",
      "48/48 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.80      0.84      0.82       874\n",
      "    Disaster       0.77      0.71      0.74       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.78      0.78      0.78      1523\n",
      "weighted avg       0.79      0.79      0.78      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 54ms/step - loss: 0.5470 - accuracy: 0.7268 - val_loss: 0.4457 - val_accuracy: 0.8024\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.4381 - accuracy: 0.8084 - val_loss: 0.4395 - val_accuracy: 0.8116\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4304 - accuracy: 0.8182 - val_loss: 0.4319 - val_accuracy: 0.8116\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.4145 - accuracy: 0.8223 - val_loss: 0.4355 - val_accuracy: 0.8116\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3980 - accuracy: 0.8317 - val_loss: 0.4782 - val_accuracy: 0.7886\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.3729 - accuracy: 0.8399 - val_loss: 0.4402 - val_accuracy: 0.8050\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.3561 - accuracy: 0.8517 - val_loss: 0.4482 - val_accuracy: 0.8037\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.3442 - accuracy: 0.8608 - val_loss: 0.4439 - val_accuracy: 0.8063\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3295 - accuracy: 0.8700 - val_loss: 0.5040 - val_accuracy: 0.7899\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3027 - accuracy: 0.8818 - val_loss: 0.4800 - val_accuracy: 0.7991\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2909 - accuracy: 0.8823 - val_loss: 0.4841 - val_accuracy: 0.7958\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2673 - accuracy: 0.8957 - val_loss: 0.4990 - val_accuracy: 0.8004\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2437 - accuracy: 0.9025 - val_loss: 0.5223 - val_accuracy: 0.7984\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2262 - accuracy: 0.9079 - val_loss: 0.7060 - val_accuracy: 0.7965\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2075 - accuracy: 0.9176 - val_loss: 0.6114 - val_accuracy: 0.7997\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.1952 - accuracy: 0.9245 - val_loss: 0.6716 - val_accuracy: 0.7525\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.1842 - accuracy: 0.9266 - val_loss: 0.6502 - val_accuracy: 0.7827\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.1724 - accuracy: 0.9276 - val_loss: 0.7308 - val_accuracy: 0.7800\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.1499 - accuracy: 0.9412 - val_loss: 0.7419 - val_accuracy: 0.7722\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.1571 - accuracy: 0.9388 - val_loss: 0.6677 - val_accuracy: 0.7853\n",
      "48/48 [==============================] - 1s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.79      0.84      0.82       874\n",
      "    Disaster       0.77      0.71      0.74       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.78      0.78      0.78      1523\n",
      "weighted avg       0.78      0.79      0.78      1523\n",
      "\n",
      "\n",
      "\n",
      "Training LSTM with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 60ms/step - loss: 0.5284 - accuracy: 0.7555 - val_loss: 0.4509 - val_accuracy: 0.8135\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4519 - accuracy: 0.8028 - val_loss: 0.4358 - val_accuracy: 0.8024\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4294 - accuracy: 0.8149 - val_loss: 0.4348 - val_accuracy: 0.8063\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4154 - accuracy: 0.8205 - val_loss: 0.4581 - val_accuracy: 0.8116\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4151 - accuracy: 0.8171 - val_loss: 0.4302 - val_accuracy: 0.8096\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3968 - accuracy: 0.8297 - val_loss: 0.4353 - val_accuracy: 0.8096\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3934 - accuracy: 0.8296 - val_loss: 0.4380 - val_accuracy: 0.8030\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3734 - accuracy: 0.8392 - val_loss: 0.4400 - val_accuracy: 0.8076\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3651 - accuracy: 0.8430 - val_loss: 0.4739 - val_accuracy: 0.8030\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3601 - accuracy: 0.8420 - val_loss: 0.4676 - val_accuracy: 0.8050\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3459 - accuracy: 0.8509 - val_loss: 0.4656 - val_accuracy: 0.7866\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3304 - accuracy: 0.8626 - val_loss: 0.5005 - val_accuracy: 0.7978\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3239 - accuracy: 0.8644 - val_loss: 0.4669 - val_accuracy: 0.7846\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3103 - accuracy: 0.8700 - val_loss: 0.4754 - val_accuracy: 0.7735\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3031 - accuracy: 0.8703 - val_loss: 0.4592 - val_accuracy: 0.7991\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2995 - accuracy: 0.8768 - val_loss: 0.5166 - val_accuracy: 0.7919\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2548 - accuracy: 0.8967 - val_loss: 0.5883 - val_accuracy: 0.7820\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2608 - accuracy: 0.8974 - val_loss: 0.5642 - val_accuracy: 0.8050\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.2273 - accuracy: 0.9108 - val_loss: 0.5181 - val_accuracy: 0.7827\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2261 - accuracy: 0.9143 - val_loss: 0.6841 - val_accuracy: 0.7899\n",
      "48/48 [==============================] - 1s 12ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.82      0.82      0.82       874\n",
      "    Disaster       0.75      0.76      0.75       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.79      0.79      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 51ms/step - loss: 0.5725 - accuracy: 0.7044 - val_loss: 0.4558 - val_accuracy: 0.8017\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.4705 - accuracy: 0.8028 - val_loss: 0.4576 - val_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.4440 - accuracy: 0.8049 - val_loss: 0.4537 - val_accuracy: 0.7958\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.4263 - accuracy: 0.8108 - val_loss: 0.4359 - val_accuracy: 0.8142\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4152 - accuracy: 0.8189 - val_loss: 0.4448 - val_accuracy: 0.8135\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.4047 - accuracy: 0.8307 - val_loss: 0.4711 - val_accuracy: 0.8142\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.4024 - accuracy: 0.8282 - val_loss: 0.4319 - val_accuracy: 0.8096\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3801 - accuracy: 0.8417 - val_loss: 0.4488 - val_accuracy: 0.8056\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3754 - accuracy: 0.8417 - val_loss: 0.4603 - val_accuracy: 0.7997\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3571 - accuracy: 0.8458 - val_loss: 0.4535 - val_accuracy: 0.8030\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3405 - accuracy: 0.8629 - val_loss: 0.4848 - val_accuracy: 0.8011\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.3394 - accuracy: 0.8588 - val_loss: 0.4471 - val_accuracy: 0.7912\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.3217 - accuracy: 0.8685 - val_loss: 0.4958 - val_accuracy: 0.7925\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3072 - accuracy: 0.8777 - val_loss: 0.5436 - val_accuracy: 0.7840\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3042 - accuracy: 0.8773 - val_loss: 0.5153 - val_accuracy: 0.7932\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.2901 - accuracy: 0.8888 - val_loss: 0.5100 - val_accuracy: 0.7919\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.2722 - accuracy: 0.8943 - val_loss: 0.5144 - val_accuracy: 0.7965\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.2661 - accuracy: 0.8944 - val_loss: 0.5160 - val_accuracy: 0.7919\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.2607 - accuracy: 0.8947 - val_loss: 0.5830 - val_accuracy: 0.7938\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.2311 - accuracy: 0.9117 - val_loss: 0.5451 - val_accuracy: 0.7853\n",
      "48/48 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.80      0.84      0.82       874\n",
      "    Disaster       0.77      0.71      0.74       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.78      0.78      0.78      1523\n",
      "weighted avg       0.78      0.79      0.78      1523\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "models = [\n",
    "    (LSTM, 'GloVe', embedding_matrix_glove),\n",
    "    (GRU, 'GloVe', embedding_matrix_glove),\n",
    "    (LSTM, 'FastText', embedding_matrix_fasttext),\n",
    "    (GRU, 'FastText', embedding_matrix_fasttext)\n",
    "]\n",
    "\n",
    "for rnn_type, emb_type, emb_matrix in models:\n",
    "    print(f\"Training {rnn_type.__name__} with {emb_type} embeddings\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[emb_matrix], input_length=max_len, trainable=False),\n",
    "        rnn_type(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    " \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_padded, y_train_binary, epochs=20, batch_size=64, validation_data=(X_test_padded, y_test_binary))\n",
    "\n",
    "    y_pred = model.predict(X_test_padded)\n",
    "    y_pred_binary = np.round(y_pred).flatten()\n",
    "\n",
    "    target_names = ['Not Disaster', 'Disaster']\n",
    "    print(classification_report(y_test_binary, y_pred_binary, target_names=target_names))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 63ms/step - loss: 0.5064 - accuracy: 0.7627 - val_loss: 0.4398 - val_accuracy: 0.8070\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4323 - accuracy: 0.8128 - val_loss: 0.4299 - val_accuracy: 0.8122\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4217 - accuracy: 0.8133 - val_loss: 0.4301 - val_accuracy: 0.8162\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.4053 - accuracy: 0.8253 - val_loss: 0.4287 - val_accuracy: 0.8129\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3844 - accuracy: 0.8373 - val_loss: 0.4195 - val_accuracy: 0.8188\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3646 - accuracy: 0.8435 - val_loss: 0.4357 - val_accuracy: 0.8148\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3505 - accuracy: 0.8479 - val_loss: 0.4873 - val_accuracy: 0.7997\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3249 - accuracy: 0.8609 - val_loss: 0.5091 - val_accuracy: 0.8083\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3085 - accuracy: 0.8721 - val_loss: 0.4719 - val_accuracy: 0.7938\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2866 - accuracy: 0.8854 - val_loss: 0.4559 - val_accuracy: 0.7951\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2686 - accuracy: 0.8906 - val_loss: 0.4952 - val_accuracy: 0.8037\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 66ms/step - loss: 0.2493 - accuracy: 0.9020 - val_loss: 0.5926 - val_accuracy: 0.7630\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.2387 - accuracy: 0.9054 - val_loss: 0.5372 - val_accuracy: 0.7814\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2104 - accuracy: 0.9163 - val_loss: 0.6464 - val_accuracy: 0.7925\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.1996 - accuracy: 0.9232 - val_loss: 0.6780 - val_accuracy: 0.7925\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.1784 - accuracy: 0.9342 - val_loss: 0.5874 - val_accuracy: 0.7853\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.1672 - accuracy: 0.9394 - val_loss: 0.6410 - val_accuracy: 0.7741\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.1541 - accuracy: 0.9415 - val_loss: 0.6720 - val_accuracy: 0.7787\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.1418 - accuracy: 0.9499 - val_loss: 0.6944 - val_accuracy: 0.7735\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.1352 - accuracy: 0.9507 - val_loss: 0.8484 - val_accuracy: 0.7702\n",
      "48/48 [==============================] - 1s 10ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.80      0.80      0.80       874\n",
      "    Disaster       0.73      0.73      0.73       649\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.77      0.76      0.76      1523\n",
      "weighted avg       0.77      0.77      0.77      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 53ms/step - loss: 0.5570 - accuracy: 0.7057 - val_loss: 0.4725 - val_accuracy: 0.7938\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4453 - accuracy: 0.8071 - val_loss: 0.4337 - val_accuracy: 0.8096\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4427 - accuracy: 0.8105 - val_loss: 0.4457 - val_accuracy: 0.8155\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4120 - accuracy: 0.8232 - val_loss: 0.4397 - val_accuracy: 0.8155\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3950 - accuracy: 0.8328 - val_loss: 0.4196 - val_accuracy: 0.8142\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.3788 - accuracy: 0.8386 - val_loss: 0.4327 - val_accuracy: 0.8122\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3642 - accuracy: 0.8470 - val_loss: 0.4281 - val_accuracy: 0.8122\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3459 - accuracy: 0.8545 - val_loss: 0.4236 - val_accuracy: 0.8162\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3366 - accuracy: 0.8565 - val_loss: 0.4649 - val_accuracy: 0.8083\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3152 - accuracy: 0.8709 - val_loss: 0.4810 - val_accuracy: 0.7938\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2924 - accuracy: 0.8854 - val_loss: 0.4887 - val_accuracy: 0.7991\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2754 - accuracy: 0.8908 - val_loss: 0.5247 - val_accuracy: 0.7958\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2551 - accuracy: 0.8933 - val_loss: 0.4825 - val_accuracy: 0.7879\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2476 - accuracy: 0.9041 - val_loss: 0.5944 - val_accuracy: 0.7945\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.2448 - accuracy: 0.8995 - val_loss: 0.5997 - val_accuracy: 0.7899\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2060 - accuracy: 0.9236 - val_loss: 0.6413 - val_accuracy: 0.7932\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.1954 - accuracy: 0.9250 - val_loss: 0.6095 - val_accuracy: 0.7919\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.1878 - accuracy: 0.9251 - val_loss: 0.6875 - val_accuracy: 0.7892\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.1695 - accuracy: 0.9368 - val_loss: 0.5608 - val_accuracy: 0.7984\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.1575 - accuracy: 0.9374 - val_loss: 0.7539 - val_accuracy: 0.7708\n",
      "48/48 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.78      0.84      0.81       874\n",
      "    Disaster       0.76      0.68      0.72       649\n",
      "\n",
      "    accuracy                           0.77      1523\n",
      "   macro avg       0.77      0.76      0.76      1523\n",
      "weighted avg       0.77      0.77      0.77      1523\n",
      "\n",
      "\n",
      "\n",
      "Training LSTM with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 60ms/step - loss: 0.5278 - accuracy: 0.7575 - val_loss: 0.4474 - val_accuracy: 0.8011\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.4357 - accuracy: 0.8071 - val_loss: 0.4452 - val_accuracy: 0.8096\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.4311 - accuracy: 0.8131 - val_loss: 0.4417 - val_accuracy: 0.8037\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.4123 - accuracy: 0.8159 - val_loss: 0.4439 - val_accuracy: 0.7965\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4045 - accuracy: 0.8238 - val_loss: 0.4382 - val_accuracy: 0.7951\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3970 - accuracy: 0.8248 - val_loss: 0.4483 - val_accuracy: 0.8102\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3899 - accuracy: 0.8274 - val_loss: 0.4552 - val_accuracy: 0.8142\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3744 - accuracy: 0.8369 - val_loss: 0.4431 - val_accuracy: 0.7978\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3697 - accuracy: 0.8415 - val_loss: 0.4581 - val_accuracy: 0.8017\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3554 - accuracy: 0.8512 - val_loss: 0.4658 - val_accuracy: 0.7912\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3453 - accuracy: 0.8568 - val_loss: 0.4511 - val_accuracy: 0.8076\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.3243 - accuracy: 0.8644 - val_loss: 0.4671 - val_accuracy: 0.8102\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3059 - accuracy: 0.8719 - val_loss: 0.4559 - val_accuracy: 0.7991\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.2910 - accuracy: 0.8739 - val_loss: 0.5286 - val_accuracy: 0.8030\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2717 - accuracy: 0.8901 - val_loss: 0.4793 - val_accuracy: 0.7892\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.2742 - accuracy: 0.8880 - val_loss: 0.5273 - val_accuracy: 0.7919\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2441 - accuracy: 0.8985 - val_loss: 0.5803 - val_accuracy: 0.7925\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2302 - accuracy: 0.9087 - val_loss: 0.5703 - val_accuracy: 0.7971\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.2087 - accuracy: 0.9140 - val_loss: 0.6490 - val_accuracy: 0.7984\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.1927 - accuracy: 0.9228 - val_loss: 0.6604 - val_accuracy: 0.7912\n",
      "48/48 [==============================] - 1s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.81      0.83      0.82       874\n",
      "    Disaster       0.76      0.74      0.75       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.79      0.79      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 54ms/step - loss: 0.5780 - accuracy: 0.6892 - val_loss: 0.5252 - val_accuracy: 0.7965\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.4542 - accuracy: 0.8007 - val_loss: 0.4394 - val_accuracy: 0.8070\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4308 - accuracy: 0.8125 - val_loss: 0.4767 - val_accuracy: 0.7781\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4244 - accuracy: 0.8135 - val_loss: 0.4591 - val_accuracy: 0.8083\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.4156 - accuracy: 0.8232 - val_loss: 0.4629 - val_accuracy: 0.8024\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.4072 - accuracy: 0.8297 - val_loss: 0.4685 - val_accuracy: 0.8011\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3855 - accuracy: 0.8365 - val_loss: 0.4784 - val_accuracy: 0.8129\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3820 - accuracy: 0.8409 - val_loss: 0.4852 - val_accuracy: 0.7820\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3656 - accuracy: 0.8483 - val_loss: 0.4729 - val_accuracy: 0.8142\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3512 - accuracy: 0.8568 - val_loss: 0.4366 - val_accuracy: 0.8011\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.3527 - accuracy: 0.8558 - val_loss: 0.4620 - val_accuracy: 0.8056\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3336 - accuracy: 0.8668 - val_loss: 0.5498 - val_accuracy: 0.7978\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.3180 - accuracy: 0.8704 - val_loss: 0.4564 - val_accuracy: 0.8004\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.2987 - accuracy: 0.8831 - val_loss: 0.4444 - val_accuracy: 0.8024\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2807 - accuracy: 0.8890 - val_loss: 0.5441 - val_accuracy: 0.7958\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2879 - accuracy: 0.8854 - val_loss: 0.4945 - val_accuracy: 0.8017\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2600 - accuracy: 0.8979 - val_loss: 0.5098 - val_accuracy: 0.7958\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2458 - accuracy: 0.9030 - val_loss: 0.6093 - val_accuracy: 0.7951\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2393 - accuracy: 0.9072 - val_loss: 0.6038 - val_accuracy: 0.7761\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.2130 - accuracy: 0.9143 - val_loss: 0.6668 - val_accuracy: 0.7787\n",
      "48/48 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.81      0.80      0.81       874\n",
      "    Disaster       0.74      0.75      0.74       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.77      0.77      0.77      1523\n",
      "weighted avg       0.78      0.78      0.78      1523\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "models = [\n",
    "    (LSTM, 'GloVe', embedding_matrix_glove),\n",
    "    (GRU, 'GloVe', embedding_matrix_glove),\n",
    "    (LSTM, 'FastText', embedding_matrix_fasttext),\n",
    "    (GRU, 'FastText', embedding_matrix_fasttext)\n",
    "]\n",
    "\n",
    "for rnn_type, emb_type, emb_matrix in models:\n",
    "    print(f\"Training {rnn_type.__name__} with {emb_type} embeddings\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[emb_matrix], input_length=max_len, trainable=False),\n",
    "        rnn_type(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_padded, y_train_binary, epochs=20, batch_size=64, validation_data=(X_test_padded, y_test_binary))\n",
    "\n",
    "    y_pred = model.predict(X_test_padded)\n",
    "    y_pred_binary = np.round(y_pred).flatten()\n",
    "\n",
    "    target_names = ['Not Disaster', 'Disaster']\n",
    "    print(classification_report(y_test_binary, y_pred_binary, target_names=target_names))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 59ms/step - loss: 0.5141 - accuracy: 0.7565 - val_loss: 0.4362 - val_accuracy: 0.8181\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4320 - accuracy: 0.8128 - val_loss: 0.4386 - val_accuracy: 0.8076\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.4111 - accuracy: 0.8240 - val_loss: 0.4333 - val_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.4099 - accuracy: 0.8278 - val_loss: 0.4268 - val_accuracy: 0.8142\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 61ms/step - loss: 0.3835 - accuracy: 0.8319 - val_loss: 0.4294 - val_accuracy: 0.8148\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3644 - accuracy: 0.8412 - val_loss: 0.4438 - val_accuracy: 0.8024\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3538 - accuracy: 0.8507 - val_loss: 0.4246 - val_accuracy: 0.8142\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3223 - accuracy: 0.8626 - val_loss: 0.4437 - val_accuracy: 0.8043\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3038 - accuracy: 0.8721 - val_loss: 0.4759 - val_accuracy: 0.8129\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2963 - accuracy: 0.8752 - val_loss: 0.5509 - val_accuracy: 0.7938\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2570 - accuracy: 0.8952 - val_loss: 0.5754 - val_accuracy: 0.7590\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2506 - accuracy: 0.8957 - val_loss: 0.4796 - val_accuracy: 0.8083\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.2122 - accuracy: 0.9136 - val_loss: 0.5761 - val_accuracy: 0.7886\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.2059 - accuracy: 0.9164 - val_loss: 0.5315 - val_accuracy: 0.7925\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.1794 - accuracy: 0.9271 - val_loss: 0.5893 - val_accuracy: 0.7886\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.1766 - accuracy: 0.9325 - val_loss: 0.6520 - val_accuracy: 0.7958\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.1569 - accuracy: 0.9420 - val_loss: 0.6395 - val_accuracy: 0.7945\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 7s 68ms/step - loss: 0.1389 - accuracy: 0.9465 - val_loss: 0.6465 - val_accuracy: 0.7886\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 61ms/step - loss: 0.1325 - accuracy: 0.9499 - val_loss: 0.7391 - val_accuracy: 0.7722\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 60ms/step - loss: 0.1150 - accuracy: 0.9552 - val_loss: 0.7876 - val_accuracy: 0.7919\n",
      "48/48 [==============================] - 0s 8ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.83      0.81      0.82       874\n",
      "    Disaster       0.75      0.77      0.76       649\n",
      "\n",
      "    accuracy                           0.79      1523\n",
      "   macro avg       0.79      0.79      0.79      1523\n",
      "weighted avg       0.79      0.79      0.79      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with GloVe embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 51ms/step - loss: 0.5457 - accuracy: 0.7282 - val_loss: 0.5098 - val_accuracy: 0.7564\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.4513 - accuracy: 0.8018 - val_loss: 0.4408 - val_accuracy: 0.8043\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.4266 - accuracy: 0.8158 - val_loss: 0.4422 - val_accuracy: 0.8089\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4086 - accuracy: 0.8246 - val_loss: 0.4234 - val_accuracy: 0.8142\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3954 - accuracy: 0.8322 - val_loss: 0.4276 - val_accuracy: 0.8089\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.3759 - accuracy: 0.8404 - val_loss: 0.4578 - val_accuracy: 0.7984\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3624 - accuracy: 0.8512 - val_loss: 0.4312 - val_accuracy: 0.8181\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.3503 - accuracy: 0.8557 - val_loss: 0.4765 - val_accuracy: 0.8116\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.3280 - accuracy: 0.8644 - val_loss: 0.4336 - val_accuracy: 0.8083\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3055 - accuracy: 0.8759 - val_loss: 0.5457 - val_accuracy: 0.7919\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 59ms/step - loss: 0.2964 - accuracy: 0.8813 - val_loss: 0.4431 - val_accuracy: 0.8037\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 49s 511ms/step - loss: 0.2788 - accuracy: 0.8906 - val_loss: 0.5116 - val_accuracy: 0.7971\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.2714 - accuracy: 0.8872 - val_loss: 0.5983 - val_accuracy: 0.7912\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.2383 - accuracy: 0.9064 - val_loss: 0.5834 - val_accuracy: 0.7905\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2235 - accuracy: 0.9133 - val_loss: 0.5459 - val_accuracy: 0.7807\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.2084 - accuracy: 0.9197 - val_loss: 0.5852 - val_accuracy: 0.7873\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.1939 - accuracy: 0.9248 - val_loss: 0.5851 - val_accuracy: 0.7820\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.1722 - accuracy: 0.9325 - val_loss: 0.7023 - val_accuracy: 0.7945\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 57ms/step - loss: 0.1696 - accuracy: 0.9325 - val_loss: 0.9165 - val_accuracy: 0.7735\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 5s 53ms/step - loss: 0.1616 - accuracy: 0.9350 - val_loss: 0.7156 - val_accuracy: 0.7833\n",
      "48/48 [==============================] - 1s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.80      0.83      0.82       874\n",
      "    Disaster       0.76      0.71      0.74       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.78      0.77      0.78      1523\n",
      "weighted avg       0.78      0.78      0.78      1523\n",
      "\n",
      "\n",
      "\n",
      "Training LSTM with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 7s 59ms/step - loss: 0.5366 - accuracy: 0.7325 - val_loss: 0.4585 - val_accuracy: 0.8030\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.4556 - accuracy: 0.8033 - val_loss: 0.4355 - val_accuracy: 0.8089\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.4344 - accuracy: 0.8074 - val_loss: 0.4519 - val_accuracy: 0.8102\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.4229 - accuracy: 0.8151 - val_loss: 0.4560 - val_accuracy: 0.8037\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.4052 - accuracy: 0.8217 - val_loss: 0.4461 - val_accuracy: 0.8063\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 6s 61ms/step - loss: 0.4000 - accuracy: 0.8261 - val_loss: 0.4409 - val_accuracy: 0.8089\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3807 - accuracy: 0.8356 - val_loss: 0.4421 - val_accuracy: 0.7938\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 6s 61ms/step - loss: 0.3761 - accuracy: 0.8383 - val_loss: 0.4335 - val_accuracy: 0.8129\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 6s 65ms/step - loss: 0.3637 - accuracy: 0.8453 - val_loss: 0.5071 - val_accuracy: 0.8083\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 61ms/step - loss: 0.3523 - accuracy: 0.8521 - val_loss: 0.4372 - val_accuracy: 0.8083\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.3442 - accuracy: 0.8537 - val_loss: 0.4332 - val_accuracy: 0.8076\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.3256 - accuracy: 0.8622 - val_loss: 0.4694 - val_accuracy: 0.8175\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.3005 - accuracy: 0.8775 - val_loss: 0.4681 - val_accuracy: 0.7951\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 6s 62ms/step - loss: 0.2910 - accuracy: 0.8821 - val_loss: 0.4831 - val_accuracy: 0.8043\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2805 - accuracy: 0.8870 - val_loss: 0.5191 - val_accuracy: 0.7866\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2624 - accuracy: 0.8961 - val_loss: 0.5262 - val_accuracy: 0.7827\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2492 - accuracy: 0.9002 - val_loss: 0.5472 - val_accuracy: 0.8076\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2362 - accuracy: 0.9051 - val_loss: 0.4893 - val_accuracy: 0.7978\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 6s 64ms/step - loss: 0.2075 - accuracy: 0.9227 - val_loss: 0.6204 - val_accuracy: 0.7932\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 6s 63ms/step - loss: 0.2062 - accuracy: 0.9213 - val_loss: 0.6042 - val_accuracy: 0.8037\n",
      "48/48 [==============================] - 1s 9ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.77      0.94      0.85       874\n",
      "    Disaster       0.88      0.63      0.73       649\n",
      "\n",
      "    accuracy                           0.80      1523\n",
      "   macro avg       0.82      0.78      0.79      1523\n",
      "weighted avg       0.82      0.80      0.80      1523\n",
      "\n",
      "\n",
      "\n",
      "Training GRU with FastText embeddings\n",
      "Epoch 1/20\n",
      "96/96 [==============================] - 6s 53ms/step - loss: 0.5806 - accuracy: 0.6859 - val_loss: 0.4651 - val_accuracy: 0.7958\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4493 - accuracy: 0.8026 - val_loss: 0.4445 - val_accuracy: 0.8142\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.4287 - accuracy: 0.8115 - val_loss: 0.4447 - val_accuracy: 0.7978\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.4243 - accuracy: 0.8151 - val_loss: 0.4293 - val_accuracy: 0.8096\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.4146 - accuracy: 0.8235 - val_loss: 0.4399 - val_accuracy: 0.8122\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.3942 - accuracy: 0.8348 - val_loss: 0.4417 - val_accuracy: 0.8122\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 5s 54ms/step - loss: 0.3853 - accuracy: 0.8388 - val_loss: 0.4416 - val_accuracy: 0.8063\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.3765 - accuracy: 0.8396 - val_loss: 0.4926 - val_accuracy: 0.8024\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3680 - accuracy: 0.8447 - val_loss: 0.4371 - val_accuracy: 0.7991\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 6s 58ms/step - loss: 0.3641 - accuracy: 0.8491 - val_loss: 0.4523 - val_accuracy: 0.7991\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3386 - accuracy: 0.8588 - val_loss: 0.4511 - val_accuracy: 0.7997\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3377 - accuracy: 0.8624 - val_loss: 0.4330 - val_accuracy: 0.8076\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.3139 - accuracy: 0.8718 - val_loss: 0.4734 - val_accuracy: 0.7984\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2976 - accuracy: 0.8777 - val_loss: 0.4783 - val_accuracy: 0.7958\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2896 - accuracy: 0.8842 - val_loss: 0.5082 - val_accuracy: 0.7978\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2707 - accuracy: 0.8900 - val_loss: 0.5723 - val_accuracy: 0.7938\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2709 - accuracy: 0.8952 - val_loss: 0.5356 - val_accuracy: 0.8037\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2418 - accuracy: 0.9013 - val_loss: 0.6589 - val_accuracy: 0.7971\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 5s 55ms/step - loss: 0.2280 - accuracy: 0.9067 - val_loss: 0.5700 - val_accuracy: 0.7892\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 5s 56ms/step - loss: 0.2088 - accuracy: 0.9156 - val_loss: 0.7067 - val_accuracy: 0.7630\n",
      "48/48 [==============================] - 0s 7ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Not Disaster       0.83      0.74      0.78       874\n",
      "    Disaster       0.70      0.79      0.74       649\n",
      "\n",
      "    accuracy                           0.76      1523\n",
      "   macro avg       0.76      0.77      0.76      1523\n",
      "weighted avg       0.77      0.76      0.76      1523\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create models\n",
    "models = [\n",
    "    (LSTM, 'GloVe', embedding_matrix_glove),\n",
    "    (GRU, 'GloVe', embedding_matrix_glove),\n",
    "    (LSTM, 'FastText', embedding_matrix_fasttext),\n",
    "    (GRU, 'FastText', embedding_matrix_fasttext)\n",
    "]\n",
    "\n",
    "for rnn_type, emb_type, emb_matrix in models:\n",
    "    print(f\"Training {rnn_type.__name__} with {emb_type} embeddings\")\n",
    "\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim, weights=[emb_matrix], input_length=max_len, trainable=False),\n",
    "        rnn_type(128, dropout=0.2, recurrent_dropout=0.2),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train_padded, y_train_binary, epochs=20, batch_size=64, validation_data=(X_test_padded, y_test_binary))\n",
    "\n",
    "    y_pred = model.predict(X_test_padded)\n",
    "    y_pred_binary = np.round(y_pred).flatten()\n",
    "\n",
    "    target_names = ['Not Disaster', 'Disaster']\n",
    "    print(classification_report(y_test_binary, y_pred_binary, target_names=target_names))\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
